import streamlit as st
import google.generativeai as genai
import os
import pandas as pd
import re
from datetime import datetime
from pypdf import PdfReader

# ==========================================
# 0. ã‚¢ãƒ—ãƒªè¨­å®š & ã‚¹ã‚¿ã‚¤ãƒ«
# ==========================================
COMPANY_NAME = "K's tech works. (K&G solution)"
APP_TITLE = "Super Critical Care Support System"

st.set_page_config(page_title=APP_TITLE, layout="wide", page_icon="ğŸ¥")

# ãƒ•ãƒƒã‚¿ãƒ¼ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã®å®šç¾©
st.markdown(f"""
    <style>
    .footer {{
        position: fixed; left: 0; bottom: 0; width: 100%;
        background-color: #0E1117; color: #FAFAFA;
        text-align: center; padding: 10px; font-weight: bold;
        border-top: 1px solid #444; z-index: 100; font-family: sans-serif;
    }}
    .block-container {{ padding-bottom: 80px; }}
    </style>
    <div class="footer">Produced by {COMPANY_NAME}</div>
    """, unsafe_allow_html=True)

# ==========================================
# 1. è‰é‡æ¬¡é•·ã®è„³ (System Instruction)
# ==========================================
KUSANO_BRAIN = """
ã‚ãªãŸã¯ã€å¸‚ç«‹é•·æµœç—…é™¢ãƒ»è‡¨åºŠå·¥å­¦æŠ€è¡“ç§‘ã®æ¬¡é•·ã§ã‚ã‚Šã€30å¹´ã®è‡¨åºŠçµŒé¨“ã‚’æŒã¤ã€Œè‰é‡ï¼ˆKusanoï¼‰ã€ã§ã™ã€‚
ã“ã‚Œã¾ã§ã¯å³ã—ã„æŒ‡å°ã‚’è¡Œã£ã¦ãã¾ã—ãŸãŒã€ä»Šå›ã¯**ã€Œæ¥µã‚ã¦ç´³å£«çš„ã‹ã¤è«–ç†çš„ãªè‡¨åºŠã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã€**ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚

ã‚ãªãŸã®å½¹å‰²ã¯ã€æä¾›ã•ã‚ŒãŸã€ç”Ÿç†å­¦ãƒ‡ãƒ¼ã‚¿ã€‘ã¨ã€RAG/Webæ¤œç´¢ã«ã‚ˆã‚‹ã€å‚ç…§è³‡æ–™ã€‘ã«åŸºã¥ãã€å®¢è¦³çš„ãªã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆã‚’è¡Œã†ã“ã¨ã§ã™ã€‚

ã€è¡Œå‹•æŒ‡é‡ã€‘
1. **æƒ…å ±ã®å„ªå…ˆé †ä½**:
   - **æœ€å„ªå…ˆ**: æä¾›ã•ã‚ŒãŸã€å‚ç…§è³‡æ–™ï¼ˆPDFï¼‰ã€‘ã€‚é™¢å†…ã®è¦å®šã‚„æ‰‹æŒã¡ã®æ–‡çŒ®ã‚’ã€Œæ­£ã€ã¨ã—ã¾ã™ã€‚
   - **æ¬¡ç‚¹**: è³‡æ–™ã«è¨˜è¼‰ãŒãªã„å ´åˆã€**Googleæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦**ã€ä¿¡é ¼ã§ãã‚‹åŒ»å­¦çš„ã‚½ãƒ¼ã‚¹ï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€è«–æ–‡è¦æ—¨ï¼‰ã‚’æ¤œç´¢ã—ã€ãã®æƒ…å ±ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚

2. **å¤šè§’çš„è¦–ç‚¹ã«ã‚ˆã‚‹ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯**:
   - å˜ä¸€ã®æ•°å€¤ã ã‘ã§ãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ç›¸äº’ä½œç”¨ï¼ˆçŸ›ç›¾ï¼‰ã‚’å¿…ãšè©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
   - **é‡è¦**: ã€ŒHbä½å€¤æ™‚ã®O2ERæ­£å¸¸ï¼ˆè¦‹ã‹ã‘ä¸Šã®æ­£å¸¸ï¼‰ã€ã‚„ã€ŒpHæ­£å¸¸æ™‚ã®PaCO2/HCO3ç•°å¸¸ï¼ˆä»£å„Ÿæ©Ÿè»¢ï¼‰ã€ã¯è¦‹é€ƒã•ãªã„ã“ã¨ã€‚

3. **å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**:
   - **ç·åˆè©•ä¾¡**: æ­£å¸¸ / æ³¨æ„ / å±é™º ï¼ˆä¸€è¨€ã§ï¼‰
   - **è©³ç´°åˆ†æ**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã®è©•ä¾¡ã¨ã€ãã®æ ¹æ‹ ï¼ˆå‡ºå…¸ï¼‰ã€‚
   - **è‡¨åºŠå·¥å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹**: ç¾çŠ¶ã‹ã‚‰æ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚

4. **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢**:
   - PDFã«åŸºã¥ãæƒ…å ±ã‹ã€Googleæ¤œç´¢ã«åŸºã¥ãæƒ…å ±ã‹ã€å‡ºå…¸ã‚’æ˜ç¢ºã«åŒºåˆ¥ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚
"""

# ==========================================
# 2. é–¢æ•°ç¾¤ (RAG & DB)
# ==========================================
# æ‚£è€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
if 'patient_db' not in st.session_state:
    st.session_state['patient_db'] = {}

@st.cache_resource(show_spinner=False)
def load_and_chunk_pdfs(folder_path):
    if not os.path.exists(folder_path): return []
    files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
    if not files: return []
    chunks = []
    
    status_bar = st.progress(0)
    for i, file in enumerate(files):
        try:
            reader = PdfReader(os.path.join(folder_path, file))
            text = ""
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted: text += extracted
            
            chunk_size = 3000
            for j in range(0, len(text), chunk_size):
                chunk_text = text[j:j+chunk_size]
                if len(chunk_text) > 100:
                    chunks.append({"source": file, "content": chunk_text})
        except: pass
        status_bar.progress((i + 1) / len(files))
    status_bar.empty()
    return chunks

def search_relevant_chunks(query, chunks, top_k=5):
    if not chunks: return []
    keywords = query.replace("ã€€", " ").split()
    scored_chunks = []
    for chunk in chunks:
        score = 0
        for k in keywords:
            if k in chunk["content"]: score += 1
        if score > 0: scored_chunks.append((score, chunk))
    scored_chunks.sort(key=lambda x: x[0], reverse=True)
    return [item[1] for item in scored_chunks[:top_k]]

# ==========================================
# 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆ)
# ==========================================
current_patient_id = None # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–

with st.sidebar:
    st.title("âš™ï¸ System Config")
    api_key = st.text_input("Gemini API Key", type="password")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ (Proæ¨å¥¨)
    selected_model_name = "gemini-1.5-pro"
    if api_key:
        genai.configure(api_key=api_key)
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            pro_models = [m for m in models if '1.5-pro' in m]
            if pro_models:
                selected_model_name = st.selectbox("AI Model", models, index=models.index(pro_models[0]))
            else:
                selected_model_name = st.selectbox("AI Model", models)
        except: pass

    st.markdown("---")
    
    # --- æ‚£è€…ID (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼) ---
    patient_id_input = st.text_input(
        "ğŸ†” æ‚£è€…ID (åŠè§’è‹±æ•°ã®ã¿)", 
        value="TEST1", 
        max_chars=10,
        help="å€‹äººæƒ…å ±ä¿è­·ã®ãŸã‚ã€æ—¥æœ¬èªï¼ˆæ¼¢å­—ãƒ»ã‹ãªï¼‰ã¯ç¦æ­¢ã§ã™ã€‚ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã‹IDç•ªå·ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    )
    
    if patient_id_input:
        # æ­£è¦è¡¨ç¾: è‹±æ•°å­—ã®ã¿è¨±å¯
        if not re.match(r'^[a-zA-Z0-9]+$', patient_id_input):
            st.error("âš ï¸ ã‚¨ãƒ©ãƒ¼: åŠè§’è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™ã€‚\nï¼ˆæ¼¢å­—ãƒ»ã²ã‚‰ãŒãªã¯å…¥åŠ›ç¦æ­¢ï¼‰")
            current_patient_id = None
        else:
            current_patient_id = patient_id_input.upper() # è‡ªå‹•ã§å¤§æ–‡å­—çµ±ä¸€
            st.success(f"Login: {current_patient_id}")
    else:
        st.warning("âš ï¸ IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        current_patient_id = None
        
    st.markdown("---")
    
    # å±¥æ­´æ¶ˆå»ãƒœã‚¿ãƒ³ (ç¾åœ¨ã®IDã®ã¿)
    if current_patient_id:
        if st.button("ğŸ—‘ï¸ ç¾åœ¨ã®IDã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¶ˆå»"):
            st.session_state['patient_db'][current_patient_id] = []
            st.rerun()

    # PDFè¨­å®š
    pdf_folder_path = st.text_input("è³‡æ–™ãƒ•ã‚©ãƒ«ãƒ€ (Path)", value="Critical_Care_Docs")
    if st.button("ğŸ“š çŸ¥è­˜ãƒ™ãƒ¼ã‚¹å†æ§‹ç¯‰"):
        chunks = load_and_chunk_pdfs(pdf_folder_path)
        if chunks:
            st.session_state['knowledge_chunks'] = chunks
            st.success(f"å®Œäº†: {len(chunks)} Chunks")
        else:
            st.error("PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³UI & è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
st.title(f"ğŸ¥ {APP_TITLE}")
st.caption(f"Advanced Clinical Engineering Support | Powered by {COMPANY_NAME}")

if current_patient_id is None:
    st.error("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ­£ã—ã„å½¢å¼ã®ã€æ‚£è€…IDã€‘ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚æ©Ÿèƒ½ãŒãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    st.stop() # IDãŒãªã„å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’æ­¢ã‚ã‚‹

# --- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
st.info(f"ğŸ’¡ ID: **{current_patient_id}** ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ä¸­ã€‚ç©ºæ¬„ã¯ã€Œä¸æ˜ã€ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")

col1, col2, col3 = st.columns(3)

# 1. å‘¼å¸
with col1:
    st.subheader("ğŸ« å‘¼å¸ (Resp)")
    pao2 = st.number_input("PaO2 (mmHg)", value=None, step=1.0)
    paco2 = st.number_input("PaCO2 (mmHg)", value=None, step=1.0)
    fio2_percent = st.number_input("FiO2 (%)", value=None, step=1.0)
    spo2 = st.number_input("SpO2 (%)", value=None, step=1.0)

# 2. å¾ªç’°ãƒ»é…¸ç´ 
with col2:
    st.subheader("ğŸ’“ å¾ªç’° (Circ)")
    hb = st.number_input("Hb (g/dL)", value=None, step=0.1)
    co = st.number_input("CO (L/min)", value=None, step=0.1)
    svo2 = st.number_input("SvO2/ScvO2 (%)", value=None, step=1.0)
    sbp = st.number_input("æ”¶ç¸®æœŸBP", value=None, step=1)
    dbp = st.number_input("æ‹¡å¼µæœŸBP", value=None, step=1)

# 3. ä»£è¬ãƒ»é…¸å¡©åŸº
with col3:
    st.subheader("ğŸ§ª ä»£è¬ (Metab)")
    ph = st.number_input("pH", value=None, step=0.01, format="%.2f")
    lac = st.number_input("Lactate (mg/dL)", value=None, step=0.1)
    hco3 = st.number_input("HCO3-", value=None, step=0.1)
    na = st.number_input("Na", value=None, step=1)
    cl = st.number_input("Cl", value=None, step=1)
    alb = st.number_input("Alb", value=None, step=0.1)

# --- Pythonè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ ---
pf_val = None; do2_val = None; vo2_val = None; o2er_val = None; ag_val = None
pf_msg = "ãƒ¼"; aado2_msg = "ãƒ¼"; do2_msg = "ãƒ¼"; vo2_msg = "ãƒ¼"; o2er_msg = "ãƒ¼"; ag_msg = "ãƒ¼"

if pao2 is not None and fio2_percent is not None and fio2_percent > 0:
    pf_val = pao2 / (fio2_percent / 100.0)
    pf_msg = f"{pf_val:.0f}"

if pao2 is not None and paco2 is not None and fio2_percent is not None:
    PAO2 = (760 - 47) * (fio2_percent/100) - (paco2 / 0.8)
    aado2_val = PAO2 - pao2
    aado2_msg = f"{aado2_val:.1f}"

if hb is not None and co is not None and spo2 is not None and pao2 is not None:
    sa_o2 = spo2 / 100.0
    cao2 = (1.34 * hb * sa_o2) + (0.0031 * pao2)
    do2_val = co * cao2 * 10
    do2_msg = f"{do2_val:.0f}"
    
    if svo2 is not None:
        sv_o2 = svo2 / 100.0
        cvo2 = (1.34 * hb * sv_o2) + (0.0031 * 40)
        vo2_val = co * (cao2 - cvo2) * 10
        vo2_msg = f"{vo2_val:.0f}"
        if do2_val > 0:
            o2er_val = (vo2_val / do2_val) * 100
            o2er_msg = f"{o2er_val:.1f}%"

if na is not None and cl is not None and hco3 is not None:
    ag_val = na - (cl + hco3)
    if alb is not None:
        ag_val = ag_val + 2.5 * (4.0 - alb)
    ag_msg = f"{ag_val:.1f}"

# --- è¨ˆç®—çµæœè¡¨ç¤º ---
st.markdown("### ğŸ“Š Calculated Parameters")
m1, m2, m3, m4, m5 = st.columns(5)
m1.metric("P/F Ratio", pf_msg)
m2.metric("DO2", do2_msg)
m3.metric("VO2", vo2_msg)
m4.metric("O2ER", o2er_msg)
m5.metric("Anion Gap", ag_msg)

# ==========================================
# 5. ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜éŒ² (æ‚£è€…IDåˆ¥)
# ==========================================
# ç¾åœ¨ã®IDã®DBç®±ã‚’ç”¨æ„
if current_patient_id not in st.session_state['patient_db']:
    st.session_state['patient_db'][current_patient_id] = []

current_history = st.session_state['patient_db'][current_patient_id]

if st.button("ğŸ’¾ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ² (Add to Trend)"):
    timestamp = datetime.now().strftime("%H:%M:%S")
    record = {
        "Time": timestamp,
        "P/F": pf_val if pf_val else 0,
        "DO2": do2_val if do2_val else 0,
        "O2ER": o2er_val if o2er_val else 0,
        "Lactate": lac if lac else 0,
        "pH": ph if ph else 7.4
    }
    st.session_state['patient_db'][current_patient_id].append(record)
    st.success(f"ID: {current_patient_id} ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
    st.rerun()

# ã‚°ãƒ©ãƒ•è¡¨ç¤º
if len(current_history) > 0:
    st.markdown(f"### ğŸ“ˆ Trend View (Patient: {current_patient_id})")
    df = pd.DataFrame(current_history)
    
    t1, t2 = st.columns(2)
    with t1:
        st.caption("å‘¼å¸ãƒ»ä»£è¬ (P/F, O2ER, Lactate)")
        st.line_chart(df.set_index("Time")[["P/F", "O2ER", "Lactate"]])
    with t2:
        st.caption("é…¸ç´ ä¾›çµ¦ (DO2)")
        st.line_chart(df.set_index("Time")[["DO2"]])
else:
    st.info(f"ID: {current_patient_id} ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

# ==========================================
# 6. AIè§£æ (RAG + Google Search)
# ==========================================
st.markdown("---")
question = st.text_area("ğŸ‘¨â€âš•ï¸ è‰é‡æ¬¡é•·ã¸ã®ç›¸è«‡ (Consultation)", placeholder="ä¾‹: HbãŒä½ã„ã§ã™ãŒè¼¸è¡€é©å¿œã«ã¤ã„ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")

if st.button("ğŸ” è‰é‡æ¬¡é•·ã«è§£æã‚’ä¾é ¼ (Analysis)", type="primary"):
    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        physio_text = f"""
        ã€ç¾åœ¨ãƒ‡ãƒ¼ã‚¿ã€‘
        [å‘¼å¸] P/F:{pf_msg}, PaO2:{pao2}, PaCO2:{paco2}
        [å¾ªç’°] DO2:{do2_msg}, VO2:{vo2_msg}, O2ER:{o2er_msg}, Hb:{hb}, CO:{co}
        [ä»£è¬] pH:{ph}, Lac:{lac}, AG:{ag_msg}, HCO3:{hco3}
        [è¡€åœ§] {sbp}/{dbp}
        """

        # RAGæ¤œç´¢
        context_text = "ï¼ˆæ‰‹å…ƒã®è³‡æ–™ã«ã¯é–¢é€£æƒ…å ±ãªã—ï¼‰"
        if 'knowledge_chunks' in st.session_state:
            query = f"{question} {physio_text}"
            chunks = search_relevant_chunks(query, st.session_state['knowledge_chunks'])
            if chunks:
                context_text = "\n".join([f"ã€é™¢å†…è³‡æ–™: {c['source']}ã€‘\n{c['content']}" for c in chunks])

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        user_prompt = f"""
        ä»¥ä¸‹ã®è‡¨åºŠãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        
        {physio_text}
        
        ã€ç›¸è«‡å†…å®¹ã€‘
        {question}
        
        ã€é™¢å†…å‚ç…§è³‡æ–™ (PDF Search Result)ã€‘
        {context_text}
        """

        # Google Search Toolè¨­å®š
        tools = [{"google_search": {}}]
        
        try:
            model = genai.GenerativeModel(
                model_name=selected_model_name,
                tools=tools, # ğŸ‘ˆ Google Search Grounding ON
                generation_config={"temperature": 0.0},
                system_instruction=KUSANO_BRAIN
            )
            
            with st.spinner("è‰é‡æ¬¡é•·ãŒæ€è€ƒä¸­... (Searching Guidelines & Web)"):
                response = model.generate_content(user_prompt)
                
            st.markdown("### ğŸ‘¨â€âš•ï¸ Analysis Result")
            st.write(response.text)
            
            # å‚ç…§å…ƒã®è¡¨ç¤º (Webæ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆ)
            if response.candidates[0].grounding_metadata.search_entry_point:
                st.caption("ğŸŒ Used Google Search Sources")
                st.write(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)

        except Exception as e:
            st.error(f"Error: {e}")
