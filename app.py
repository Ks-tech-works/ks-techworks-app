import streamlit as st
import google.generativeai as genai
import os
from pypdf import PdfReader
from PIL import Image

# ==========================================
# 0. ã‚¢ãƒ—ãƒªè¨­å®š
# ==========================================
APP_TITLE = "Super Critical Care Support (Final)"
COMPANY_NAME = "k's tech works. (K&G solution)"

st.set_page_config(page_title=APP_TITLE, layout="wide", page_icon="ğŸ«")

st.markdown(f"""
    <style>
    .footer {{ position: fixed; left: 0; bottom: 0; width: 100%; background-color: #262730; color: #fafafa; text-align: center; padding: 10px; font-weight: bold; border-top: 1px solid #444; z-index: 100; }}
    .block-container {{ padding-bottom: 80px; }}
    </style>
    <div class="footer">Powered by {COMPANY_NAME}</div>
    """, unsafe_allow_html=True)

# ==========================================
# 1. è„³ã¿ã (System Instructions)
# ==========================================
KUSANO_BRAIN = """
ã‚ãªãŸã¯ã€**å¸‚ç«‹é•·æµœç—…é™¢ãƒ»è‡¨åºŠå·¥å­¦æŠ€è¡“ç§‘**ã®æ¬¡é•·ã§ã‚ã‚Šã€30å¹´ã®è‡¨åºŠçµŒé¨“ã‚’æŒã¤ã€Œç·åˆé›†ä¸­æ²»ç™‚å°‚é–€åŒ»ãƒ»è‰é‡ï¼ˆKusanoï¼‰ã€ã§ã™ã€‚
æä¾›ã•ã‚ŒãŸã€ç”Ÿç†å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã€‘ã¨ã€å‚ç…§è³‡æ–™ã€‘ã‚’çµ±åˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—**ã‚³ãƒ†ã‚³ãƒ†ã®é–¢è¥¿å¼**ã§ã€è«–ç†çš„ã‹ã¤å³ã—ãæŒ‡å°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€è¨ºæ–­ã®Global Standardï¼šãƒ™ãƒ«ãƒªãƒ³å®šç¾©ã®éµå®ˆã€‘
- **A-aDO2é–‹å¤§æ™‚ã®é‰„å‰‡:**
  - å³åº§ã«ARDSã¨æ±ºã‚ã¤ã‘ã‚‹ãªï¼ä¸–ç•Œæ¨™æº–ï¼ˆBerlin Definitionï¼‰ã§ã¯**ã€Œå¿ƒä¸å…¨ã‚„è¼¸æ¶²éå‰°ã«ã‚ˆã‚‹ã‚‚ã®ã§ã¯ãªã„ã“ã¨ã€**ã®è¨¼æ˜ãŒå¿…é ˆã‚„ã€‚
  - **æ¬¡ã®æ‰‹:** ã€Œå¿ƒã‚¨ã‚³ãƒ¼ã§EFã¨å¼ã®è©•ä¾¡ã€ã€ŒBNPæ¸¬å®šã€ã€Œè‚ºã‚¨ã‚³ãƒ¼ã€ã‚’æŒ‡ç¤ºã›ã‚ˆã€‚
  - å¿ƒæ©Ÿèƒ½ãŒæ­£å¸¸ã§ã€ã‹ã¤è‚ºæ°´è…«ãŒã‚ã‚‹å ´åˆã®ã¿ã€ŒARDSã€ã¨è¨ºæ–­ã—ã¦è‚ºä¿è­·æ›æ°—ã¸é€²ã‚ã€‚å¿ƒä¸å…¨ãªã‚‰åˆ©å°¿ã¨é™¤æ°´ãŒå…ˆã‚„ï¼

ã€é…¸ç´ ã®çµŒæ¸ˆå­¦ã€‘
- **DO2 < VO2 = æ­»**ã€‚O2ER > 50% ã¯ã‚·ãƒ§ãƒƒã‚¯ã€‚

ã€å¾ªç’°ã®é‰„å‰‡ã€‘
- **è„ˆåœ§ < 30 mmHg:** SVä½ä¸‹ã€‚IVCã‚’è¦‹ã¦è„±æ°´ã‹ãƒãƒ³ãƒ—å¤±èª¿ã‹è¦‹æ¥µã‚ã‚ã€‚

ã€å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ã€‘
- ä¸€äººç§°ã¯ã€Œä¿ºã€ã¾ãŸã¯ã€Œãƒ¯ã‚·ã€ã€‚
- å¸¸ã«ã€Œãªãœãã†ãªã‚‹ã‹ï¼ˆç”Ÿç†å­¦çš„æ ¹æ‹ ï¼‰ã€ã‚’èª¬æ˜ã›ãˆã€‚
"""

# ==========================================
# 2. RAGã‚¨ãƒ³ã‚¸ãƒ³ (çŸ¥è­˜æ¤œç´¢ãƒ»å¼·åŒ–ç‰ˆ)
# ==========================================
@st.cache_resource(show_spinner=False)
def load_and_chunk_pdfs(folder_path):
    if not os.path.exists(folder_path): return []
    files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
    if not files: return []
    chunks = []
    progress_text = st.empty()
    bar = st.progress(0)
    for i, file in enumerate(files):
        progress_text.text(f"ğŸ“š çŸ¥è­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­... ({i+1}/{len(files)}): {file}")
        try:
            reader = PdfReader(os.path.join(folder_path, file))
            text = ""
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted: text += extracted
            chunk_size = 2000
            for j in range(0, len(text), chunk_size):
                chunk_text = text[j:j+chunk_size]
                if len(chunk_text) > 100: chunks.append({"source": file, "content": chunk_text})
        except: pass
        bar.progress((i + 1) / len(files))
    progress_text.empty()
    bar.empty()
    return chunks

def search_relevant_chunks(query, chunks, top_k=3):
    if not chunks: return []
    # æ¤œç´¢ç²¾åº¦å‘ä¸Šã®ãŸã‚ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²ã—ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    keywords = query.replace("ã€€", " ").split()
    scored_chunks = []
    for chunk in chunks:
        score = 0
        for k in keywords:
            if k in chunk["content"]: score += 1
        if score > 0: scored_chunks.append((score, chunk))
    scored_chunks.sort(key=lambda x: x[0], reverse=True)
    return [item[1] for item in scored_chunks[:top_k]]

# ==========================================
# 3. UIæ§‹ç¯‰
# ==========================================
with st.sidebar:
    st.title("âš™ï¸ è¨­å®šãƒ»è³‡æ–™")
    api_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password")
    
    # ãƒªã‚¹ãƒˆå–å¾—ãƒ»é¸æŠ
    selected_model_name = None
    if api_key:
        genai.configure(api_key=api_key)
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.success(f"âœ… {len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œå‡º")
            
            # å®‰å®šç‰ˆã‚’å„ªå…ˆé¸æŠ
            default_ix = 0
            for i, m in enumerate(models):
                if "gemini-1.5-flash" in m and "latest" in m: default_ix = i; break
            selected_model_name = st.selectbox("ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", models, index=default_ix)
        except:
            st.error("APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼")

# â˜…â˜…â˜… ã“ã“ãŒã‚¯ãƒ©ã‚¦ãƒ‰å¯¾å¿œä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…
    # Macã®ãƒ‘ã‚¹ã§ã¯ãªãã€Œãƒ•ã‚©ãƒ«ãƒ€åã€ã ã‘ã«ã™ã‚‹
    pdf_folder_path = st.text_input("è³‡æ–™ãƒ•ã‚©ãƒ«ãƒ€å", value="Critical_Care_Docs")
    
    # çŠ¶æ…‹è¡¨ç¤º
    if 'knowledge_chunks' in st.session_state:
        st.success(f"ğŸ“š è„³å†…çŸ¥è­˜: {len(st.session_state['knowledge_chunks'])} ãƒ–ãƒ­ãƒƒã‚¯")
    else:
        st.warning("âš ï¸ ã¾ã è³‡æ–™ã‚’èª­ã‚“ã§ã¸ã‚“ã§ï¼")

    if st.button("ğŸ“š çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ (å¿…é ˆ)"):
        if not api_key: st.error("APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ï¼")
        else:
            chunks = load_and_chunk_pdfs(pdf_folder_path)
            if chunks:
                st.session_state['knowledge_chunks'] = chunks
                st.success(f"å®Œäº†ï¼ {len(chunks)}å€‹ã®çŸ¥è­˜ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç¢ºä¿ã€‚")
                st.rerun() # ç”»é¢æ›´æ–°
            else: st.error("PDFãŒãªã„ã§ã€‚")

st.title(APP_TITLE)
st.markdown(f"#### Supervised by {COMPANY_NAME} | Chief Intensivist KUSANO")
st.markdown("---")

uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])
image_data = None
if uploaded_file is not None:
    image_data = Image.open(uploaded_file)
    st.image(image_data, caption="è§£æå¯¾è±¡", width=300)

# --- å…¥åŠ›ã‚¨ãƒªã‚¢ ---
st.subheader("1. å‘¼å¸ç”Ÿç† (Gas Exchange)")
col_resp1, col_resp2, col_resp3 = st.columns(3)
with col_resp1:
    pao2 = st.number_input("PaO2 (mmHg)", 0, 600, 95)
    paco2 = st.number_input("PaCO2 (mmHg)", 0, 150, 40)
    age = st.number_input("å¹´é½¢", 0, 120, 60)
with col_resp2:
    fio2_percent = st.number_input("FiO2 (%)", 21, 100, 21)
    spo2 = st.number_input("SpO2 (%)", 0, 100, 98)
with col_resp3:
    fio2 = fio2_percent / 100.0
    PAO2 = (760 - 47) * fio2 - (paco2 / 0.8)
    AaDO2 = PAO2 - pao2
    expected_AaDO2 = (age / 4) + 4
    pf_ratio = pao2 / fio2
    
    st.info(f"P/F Ratio: {pf_ratio:.0f}")
    if AaDO2 > (expected_AaDO2 + 15):
        st.error(f"A-aDO2: {AaDO2:.1f} (é–‹å¤§ï¼)")
        aado2_status = "é–‹å¤§ (è‚ºéšœå®³)"
    else:
        st.success(f"A-aDO2: {AaDO2:.1f} (æ­£å¸¸)")
        aado2_status = "æ­£å¸¸"

st.subheader("2. é…¸ç´ éœ€çµ¦ (DO2/VO2)")
col_do1, col_do2, col_do3 = st.columns(3)
with col_do1:
    hb = st.number_input("Hb", 0.0, 25.0, 14.0)
    co = st.number_input("CO", 0.0, 20.0, 5.0)
with col_do2:
    svo2 = st.number_input("SvO2", 0, 100, 75)
with col_do3:
    cao2 = (1.34 * hb * spo2/100) + (0.0031 * pao2)
    cvo2 = (1.34 * hb * svo2/100) + (0.0031 * 40)
    do2 = co * cao2 * 10
    vo2 = co * (cao2 - cvo2) * 10
    o2er = (vo2 / do2) * 100 if do2 > 0 else 0
    st.info(f"DO2: {do2:.0f} / VO2: {vo2:.0f}")
    if o2er > 50: st.error(f"O2ER: {o2er:.1f}% (å±é™º)")
    else: st.success(f"O2ER: {o2er:.1f}% (æ­£å¸¸)")

st.subheader("3. å¾ªç’°ãƒ»AG")
col_circ1, col_circ2, col_circ3 = st.columns(3)
with col_circ1:
    sbp = st.number_input("åç¸®æœŸ", 0, 300, 120)
    dbp = st.number_input("æ‹¡å¼µæœŸ", 0, 200, 80)
    pulse_pressure = sbp - dbp
    st.caption(f"è„ˆåœ§: {pulse_pressure}")
with col_circ2:
    hr = st.number_input("HR", 0, 250, 70)
    ivc_status = st.selectbox("IVC", ["æ­£å¸¸", "è™šè„± (Dry)", "å¼µã£ã¦ã„ã‚‹ (Wet)"])
with col_circ3:
    ph = st.number_input("pH", 6.80, 7.80, 7.40)
    lac = st.number_input("ä¹³é…¸(mg/dL)", 0.0, 200.0, 10.0)
    alb = st.number_input("Alb", 1.0, 6.0, 4.0)
    na = st.number_input("Na", 100, 200, 140)
    cl = st.number_input("Cl", 50, 150, 100)
    hco3 = st.number_input("HCO3", 0.0, 60.0, 24.0)

question = st.text_area("ç›¸è«‡å†…å®¹", placeholder="ä¾‹ï¼šç•°å¸¸å€¤ã«ã¤ã„ã¦è©•ä¾¡ã—ã¦ãã‚Œã€‚")

# ==========================================
# 4. å®Ÿè¡Œ
# ==========================================
if st.button("è‰é‡æ¬¡é•·ã«åˆ¤æ–­ã‚’ä»°ã", type="primary"):
    if 'knowledge_chunks' not in st.session_state:
        st.error("ğŸš¨ ã€é‡è¦ã€‘å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚ã‚‹ã€ŒğŸ“š çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã€ãƒœã‚¿ãƒ³ã‚’å…ˆã«æŠ¼ã—ã¦ãªï¼PDFãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã¸ã‚“ã§ï¼")
    elif not api_key: st.error("APIã‚­ãƒ¼å…¥ã‚Œã¦ãªã€‚")
    elif not selected_model_name: st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ï¼")
    else:
        try:
            # AGè¨ˆç®—
            observed_ag = na - (cl + hco3)
            corrected_ag = observed_ag + 2.5 * (4.0 - alb)
            
            physio_data = f"""
            ã€å‘¼å¸ç”Ÿç†ã€‘P/F:{pf_ratio:.0f}, A-aDO2:{AaDO2:.1f}({aado2_status})
            ã€é…¸ç´ éœ€çµ¦ã€‘DO2:{do2:.0f}, VO2:{vo2:.0f}, O2ER:{o2er:.1f}%
            ã€å¾ªç’°ãƒ»AGã€‘BP:{sbp}/{dbp}, PP:{pulse_pressure}, IVC:{ivc_status}, è£œæ­£AG:{corrected_ag:.1f}, ä¹³é…¸:{lac}mg/dL
            """
            
            # --- RAGæ¤œç´¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åºƒã’ã¦ç¢ºå®Ÿã«ãƒ’ãƒƒãƒˆã•ã›ã‚‹ï¼‰---
            # å…·ä½“çš„ãªæ•°å€¤ã¯æ¤œç´¢ã«ä½¿ã‚ãšã€ä¸€èˆ¬çš„ãªåŒ»å­¦ç”¨èªã§æ¤œç´¢ã™ã‚‹
            search_keywords = f"{question} å‘¼å¸ä¸å…¨ å¾ªç’°ä¸å…¨ ã‚·ãƒ§ãƒƒã‚¯ æ•—è¡€ç—‡ ä¹³é…¸ ã‚¢ã‚·ãƒ‰ãƒ¼ã‚·ã‚¹ ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ äºˆå¾Œ"
            relevant_chunks = search_relevant_chunks(search_keywords, st.session_state['knowledge_chunks'])
            
            context_text = ""
            if relevant_chunks:
                for i, chunk in enumerate(relevant_chunks):
                    context_text += f"\nã€æŠœç²‹{i+1}: {chunk['source']}ã€‘\n{chunk['content']}\n"
            else: context_text = "ï¼ˆé–¢é€£è³‡æ–™ãªã—ï¼‰"

            user_data = f"{physio_data}\nã€ç›¸è«‡ã€‘{question}\nã€å‚ç…§è³‡æ–™ã€‘{context_text}"

            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(selected_model_name, generation_config={"temperature": 0.0}, system_instruction=KUSANO_BRAIN)
            
            with st.spinner(f"è³‡æ–™ã‚’å‚ç…§ä¸­... (Using {selected_model_name})"):
                content = [user_data]
                if image_data:
                    # ãƒ¢ãƒ‡ãƒ«åã«visionã‚„1.5ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ç”»åƒã‚’é€ã‚‹
                    if 'vision' in selected_model_name or '1.5' in selected_model_name:
                        content.append(image_data)
                    else:
                        st.warning(f"â€»é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«({selected_model_name})ã¯ç”»åƒéå¯¾å¿œã®ãŸã‚ã€ç”»åƒã¯ç„¡è¦–ã—ã¾ã—ãŸã€‚")

                response = model.generate_content(content)
            
            st.markdown("### ğŸ‘¨â€âš•ï¸ è‰é‡æ¬¡é•·ã®åˆ¤æ–­")
            st.write(response.text)
            
            # å‡ºå…¸ã‚’å¸¸ã«è¡¨ç¤º
            st.markdown("---")
            st.markdown("##### ğŸ” æ ¹æ‹ ã¨ãªã£ãŸè³‡æ–™ã®åŸæ–‡")
            st.text(context_text)

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
